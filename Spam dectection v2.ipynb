{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required modules/packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import scipy as sp\n",
    "import datetime\n",
    "import pytz\n",
    "import graphviz\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.svm.libsvm import cross_validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from random import randint\n",
    "\n",
    "## Elastic Search for Metrics\n",
    "from datetime import datetime\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB         \n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# KNN Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Decision tree \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Random forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Gradient Booster Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading file and looking into the dimensions of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                  text  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"SMSSpamCollection.tsv\",sep='\\t',names=['label','text'])\n",
    "pd.set_option('display.max_colwidth',100)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>0.865937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.134063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     label\n",
       "label          \n",
       "ham    0.865937\n",
       "spam   0.134063"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(raw_data.shape)\n",
    "pd.crosstab(raw_data['label'],columns = 'label',normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Test Train Fit\n",
    "\n",
    "# Define X and y.\n",
    "X = raw_data.text\n",
    "y = raw_data.label\n",
    "\n",
    "# Split the new DataFrame into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99, test_size= 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Null Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Ham: 0.8624401913875598\n",
      "Percent Spam: 0.13755980861244022\n"
     ]
    }
   ],
   "source": [
    "# Calculate null accuracy.\n",
    "y_test_binary = np.where(y_test=='ham', 1, 0) # five stars become 1, one stars become 0\n",
    "print('Percent Ham:', y_test_binary.mean())\n",
    "print('Percent Spam:', 1 - y_test_binary.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to cleanup the data through pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk import sent_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class NLTKPreprocessor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, stopwords=None, punct=None,\n",
    "                 lower=True, strip=True):\n",
    "        self.lower      = lower\n",
    "        self.strip      = strip\n",
    "        self.stopwords  = stopwords or set(sw.words('english'))\n",
    "        self.punct      = punct or set(string.punctuation)\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#      def fit(self, X, y=None):\n",
    "#          return self\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        return [\" \".join(doc) for doc in X]\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [\n",
    "            list(self.tokenize(doc)) for doc in X\n",
    "        ]\n",
    "\n",
    "    def tokenize(self, document):\n",
    "        # Break the document into sentences\n",
    "        for sent in sent_tokenize(document):\n",
    "            # Break the sentence into part of speech tagged tokens\n",
    "            for token, tag in pos_tag(wordpunct_tokenize(sent)):\n",
    "                # Apply preprocessing to the token\n",
    "                token = token.lower() if self.lower else token\n",
    "                token = token.strip() if self.strip else token\n",
    "                token = token.strip('_') if self.strip else token\n",
    "                token = token.strip('*') if self.strip else token\n",
    "\n",
    "                # If stopword, ignore token and continue\n",
    "                if token in self.stopwords:\n",
    "                    continue\n",
    "\n",
    "                # If punctuation, ignore token and continue\n",
    "                if all(char in self.punct for char in token):\n",
    "                    continue\n",
    "\n",
    "                # Lemmatize the token and yield\n",
    "                lemma = self.lemmatize(token, tag)\n",
    "                yield lemma\n",
    "\n",
    "    def lemmatize(self, token, tag):\n",
    "        tag = {\n",
    "            'N': wn.NOUN,\n",
    "            'V': wn.VERB,\n",
    "            'R': wn.ADV,\n",
    "            'J': wn.ADJ\n",
    "        }.get(tag[0], wn.NOUN)\n",
    "\n",
    "        return self.lemmatizer.lemmatize(token, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Metrics and Generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_metrics_push_to_es(run_id_insert, algorithm_name_insert, test_parameters_insert, score, scores_cv,test_scores_csv_means_std, y_test,y_pred):\n",
    "    \n",
    "    macro_score = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "    micro_score = precision_recall_fscore_support(y_test, y_pred, average='micro')\n",
    "    weighted_score = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "  \n",
    "\n",
    "    macro_score_insert = {'macro_precision': macro_score[0] * 100, 'macro_recall': macro_score[1]  * 100, 'macro_fscore':macro_score[2]  * 100}\n",
    "    micro_score_insert = {'micro_precision': micro_score[0] * 100, 'micro_recall': micro_score[1] * 100, 'micro_fscore':micro_score[2] * 100}\n",
    "    weighted_score_insert = {'weighted_precision': weighted_score[0] * 100, 'weighted_recall': weighted_score[1] * 100, 'weighted_fscore':weighted_score[2] * 100}\n",
    "    score_insert = {'score': score  * 100}\n",
    "    scores_cv_insert = {'score_cv': str(scores_cv)}\n",
    "\n",
    "    \n",
    "    ## Print Accuracy of the current Test\n",
    "    print(algorithm_name_insert , ' pipeline test accuracy: %.3f' % score)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    ## Push the data to ElasticSearch\n",
    "\n",
    "    ES_Metric_Insert(run_id_insert, algorithm_name_insert, test_parameters_insert, score_insert, scores_cv_insert,test_scores_csv_means_std, macro_score_insert,micro_score_insert,weighted_score_insert)\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pushing Data into Elastic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ES_Metric_Insert(run_id_insert,algorithm_name, test_parameters, score, scores_cv, test_scores_csv_means_std, macro_scores, micro_scores, weighted_scores):\n",
    "    es = Elasticsearch()\n",
    "    \n",
    "    final_dict = {}\n",
    "    \n",
    "    print(algorithm_name)\n",
    "    \n",
    "    my_current_time = datetime.now(tz=pytz.utc)\n",
    "    timestamp_insert = {'timestamp': my_current_time}\n",
    "    author_insert = {'author': 'Rahul'}\n",
    "    final_dict.update(run_id_insert)\n",
    "    final_dict.update(timestamp_insert)\n",
    "    final_dict.update(author_insert)\n",
    "    final_dict.update(algorithm_name)\n",
    "    final_dict.update(test_parameters)\n",
    "    final_dict.update(score)\n",
    "    final_dict.update(scores_cv)\n",
    "    final_dict.update(test_scores_csv_means_std)\n",
    "    final_dict.update(macro_scores)\n",
    "    final_dict.update(micro_scores)\n",
    "    final_dict.update(weighted_scores)\n",
    "        \n",
    "    res = es.index(index=\"ml-performance-metrics\", doc_type='text', body=final_dict)\n",
    "    es.indices.refresh(index=\"ml-performance-metrics\")\n",
    "\n",
    "\n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Naive Bayes to predict the ham vs spam label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB With CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Algorithm_Name': 'Naive Bayes classifier'}  pipeline test accuracy: 98.206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cv_nb_features = []    \n",
    "\n",
    "pipe_cv_nb_features.append(('vect', CountVectorizer( tokenizer=LemmaTokenizer(), \n",
    "                                             lowercase=False, \n",
    "                                             min_df=1,\n",
    "                                             max_features=100000, \n",
    "                                             ngram_range=(1, 4), \n",
    "                                             stop_words='english', \n",
    "                                             decode_error='replace')))\n",
    "pipe_cv_nb_features.append(('nb', MultinomialNB()))\n",
    "\n",
    "pipe_cv_nb = Pipeline(pipe_cv_nb_features)\n",
    "\n",
    "pipe_cv_nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_cv_nb.predict(X_test)\n",
    "\n",
    "score_cv_nb_cv = pipe_cv_nb.score(X_test, y_test) * 100\n",
    "\n",
    "algorithm_name_insert = {'Algorithm_Name':'Naive Bayes classifier'}\n",
    "test_parameters_insert = {'vectorizer' : 'CountVectorizer', 'lowercase':'false','min_df': 1, 'max_features': 100000,'ngram_range': '1-4'}\n",
    "\n",
    "calculate_metrics_push_to_es(algorithm_name_insert, test_parameters_insert, score_cv_nb_cv, y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB With TfdifVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=False, max_df=1.0, max_features=100000, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...True,\n",
      "        vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])\n",
      "{'Algorithm_Name': 'Naive Bayes classifier'}  pipeline test accuracy: 0.970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_tfdif_nb_features = []\n",
    "\n",
    "\n",
    "#pipe_tfdif_nb_features.append(('preprocessor', NLTKPreprocessor()))\n",
    "pipe_tfdif_nb_features.append(('vect', TfidfVectorizer(stop_words='english', \n",
    "                                             lowercase=False, \n",
    "                                             min_df=1,\n",
    "                                             max_features=100000, \n",
    "                                             ngram_range=(1, 1))))\n",
    "\n",
    "pipe_tfdif_nb_features.append(('nb', MultinomialNB()))\n",
    "\n",
    "pipe_tfdif_nb = Pipeline(pipe_tfdif_nb_features)\n",
    "\n",
    "pipe_tfdif_nb.fit(X_train, y_train)\n",
    "\n",
    "print(pipe_tfdif_nb)\n",
    "\n",
    "y_pred = pipe_tfdif_nb.predict(X_test)\n",
    "\n",
    "score_cv_nb_tfidf = pipe_tfdif_nb.score(X_test, y_test)\n",
    "\n",
    "algorithm_name_insert = {'Algorithm_Name':'Naive Bayes classifier'}\n",
    "\n",
    "test_parameters_insert = {'vectorizer': 'Tfidf', 'lowercase':'false','min_df': 1, 'max_features': 100000,'ngram_range': '1-1'}\n",
    "\n",
    "\n",
    "calculate_metrics_push_to_es(algorithm_name_insert, test_parameters_insert, score_cv_nb_tfidf, y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Algorithm_Name': 'MultinomialNB'}  pipeline test accuracy: 0.970\n",
      "{'Algorithm_Name': 'MultinomialNB'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Algorithm_Name': 'SVC'}  pipeline test accuracy: 0.862\n",
      "{'Algorithm_Name': 'SVC'}\n",
      "{'Algorithm_Name': 'KNeighborsClassifier'}  pipeline test accuracy: 0.918\n",
      "{'Algorithm_Name': 'KNeighborsClassifier'}\n",
      "{'Algorithm_Name': 'DecisionTreeClassifier'}  pipeline test accuracy: 0.970\n",
      "{'Algorithm_Name': 'DecisionTreeClassifier'}\n",
      "{'Algorithm_Name': 'RandomForestClassifier'}  pipeline test accuracy: 0.964\n",
      "{'Algorithm_Name': 'RandomForestClassifier'}\n",
      "{'Algorithm_Name': 'GradientBoostingClassifier'}  pipeline test accuracy: 0.952\n",
      "{'Algorithm_Name': 'GradientBoostingClassifier'}\n",
      "{'Algorithm_Name': 'LogisticRegression'}  pipeline test accuracy: 0.950\n",
      "{'Algorithm_Name': 'LogisticRegression'}\n"
     ]
    }
   ],
   "source": [
    "pipe_spam_ham = []\n",
    "pipe_spam_ham_features = []\n",
    "\n",
    "run_id = randint(100000, 999999)\n",
    "\n",
    "\n",
    "#pipe_tfdif_nb_features.append(('preprocessor', NLTKPreprocessor()))\n",
    "pipe_spam_ham_features.append(('vect', TfidfVectorizer(stop_words='english', \n",
    "                                             lowercase=False, \n",
    "                                             min_df=1,\n",
    "                                             max_features=100000, \n",
    "                                             ngram_range=(1, 1))))\n",
    "\n",
    "## Initializing the classifier to Naieve Bayes\n",
    "pipe_spam_ham_features.append(('clf', MultinomialNB()))\n",
    "\n",
    "## Putting together the various classification algorithms to use\n",
    "clfs = []\n",
    "clfs.append(MultinomialNB())\n",
    "clfs.append(SVC())\n",
    "clfs.append(KNeighborsClassifier(n_neighbors=3))\n",
    "clfs.append(DecisionTreeClassifier())\n",
    "clfs.append(RandomForestClassifier())\n",
    "clfs.append(GradientBoostingClassifier())\n",
    "clfs.append(LogisticRegression())\n",
    "\n",
    "\n",
    "## Setting up the pipeline\n",
    "pipe_spam_ham = Pipeline(pipe_spam_ham_features)\n",
    "\n",
    "\n",
    "\n",
    "## Trying out the various possible classifiers:\n",
    "\n",
    "for classifier in clfs:\n",
    "    \n",
    "    ## Adding the classifier to be used\n",
    "    pipe_spam_ham.set_params(clf = classifier)\n",
    "    \n",
    "    ## Adding individual parameters for each individual classifier\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "       \n",
    "    pipe_spam_ham.fit(X_train, y_train)\n",
    "\n",
    "    ## Find predictions for the pipeline\n",
    "    y_pred = pipe_spam_ham.predict(X_test)\n",
    "    \n",
    "    ## Find score of predictions\n",
    "    score_pipe_spam_ham = pipe_spam_ham.score(X_test, y_test)\n",
    "\n",
    "    ## Cross Validate the scores\n",
    "    scores_pipe_spam_ham_cv = cross_validate(pipe_spam_ham, X_train, y_train, cv=2)\n",
    "    \n",
    "    \n",
    "    ## Setting up for reporting to Screen and ElasticSearch\n",
    "    \n",
    "    ## Add Run Id for each run. This helps with fishing out the correct dataset in cloud\n",
    "    run_id_insert = {'run_id' : run_id}\n",
    "    \n",
    "    ## Save Classifier name as a string\n",
    "    \n",
    "    classifier_string = str(classifier)\n",
    "    classifer_name_only = classifier_string.split(\"(\")[0]\n",
    "    \n",
    "    algorithm_name_insert = {'Algorithm_Name' : classifer_name_only}\n",
    "    \n",
    "    ## Add Classifier Parameters to output\n",
    "    test_parameters_insert = {'test_parameters' : str(pipe_spam_ham)}\n",
    "    \n",
    "    \n",
    "    ## Breaking test cv scores and calculating mean and standard Deviation of each.\n",
    "    test_scores_csv_means_std = {}\n",
    "    \n",
    "    for key, values in scores_pipe_spam_ham_cv.items():\n",
    "            key_mean = key + '_mean'\n",
    "            test_scores_csv_means_std[key_mean] = values.mean()\n",
    "            key_std = key + '_std'\n",
    "            test_scores_csv_means_std[key_std] = values.std()\n",
    "    \n",
    "    ## Send all the collected data to the metric collection and ES insert system.\n",
    "    calculate_metrics_push_to_es(run_id_insert, algorithm_name_insert, test_parameters_insert, score_pipe_spam_ham, scores_pipe_spam_ham_cv, test_scores_csv_means_std, y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
