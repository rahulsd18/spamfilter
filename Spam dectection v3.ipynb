{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required modules/packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import scipy as sp\n",
    "import datetime\n",
    "import pytz\n",
    "import graphviz\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.svm.libsvm import cross_validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from random import randint\n",
    "\n",
    "## Elastic Search for Metrics\n",
    "from datetime import datetime\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB         \n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# KNN Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Decision tree \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Random forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Gradient Booster Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading file and looking into the dimensions of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                  text  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"SMSSpamCollection.tsv\",sep='\\t',names=['label','text'])\n",
    "pd.set_option('display.max_colwidth',100)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>0.865937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.134063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     label\n",
       "label          \n",
       "ham    0.865937\n",
       "spam   0.134063"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(raw_data.shape)\n",
    "pd.crosstab(raw_data['label'],columns = 'label',normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Test Train Fit\n",
    "\n",
    "# Define X and y.\n",
    "X = raw_data.text\n",
    "y = raw_data.label\n",
    "\n",
    "# Split the new DataFrame into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99, test_size= 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Null Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Ham: 0.8624401913875598\n",
      "Percent Spam: 0.13755980861244022\n"
     ]
    }
   ],
   "source": [
    "# Calculate null accuracy.\n",
    "y_test_binary = np.where(y_test=='ham', 1, 0) # five stars become 1, one stars become 0\n",
    "print('Percent Ham:', y_test_binary.mean())\n",
    "print('Percent Spam:', 1 - y_test_binary.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to cleanup the data through pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Metrics and Generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_push_to_es(run_id_insert, algorithm_name_insert, test_parameters_insert, gs_best_parameters_pipe_spam_ham, score,test_scores_csv_means_std, y_test,y_pred):\n",
    "\n",
    "    macro_score = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "    micro_score = precision_recall_fscore_support(y_test, y_pred, average='micro')\n",
    "    weighted_score = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "  \n",
    "\n",
    "    macro_score_insert = {'macro_precision': macro_score[0] * 100, 'macro_recall': macro_score[1]  * 100, 'macro_fscore':macro_score[2]  * 100}\n",
    "    micro_score_insert = {'micro_precision': micro_score[0] * 100, 'micro_recall': micro_score[1] * 100, 'micro_fscore':micro_score[2] * 100}\n",
    "    weighted_score_insert = {'weighted_precision': weighted_score[0] * 100, 'weighted_recall': weighted_score[1] * 100, 'weighted_fscore':weighted_score[2] * 100}\n",
    "    score_insert = {'score': score}\n",
    "    \n",
    "    print(score_insert)\n",
    "    \n",
    "    ## Print Accuracy of the current Test\n",
    "    print(algorithm_name_insert , ' pipeline test accuracy: %.3f' % score)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    ## Push the data to ElasticSearch\n",
    "\n",
    "    ES_Metric_Insert(run_id_insert, algorithm_name_insert, test_parameters_insert,gs_best_parameters_pipe_spam_ham, score_insert,test_scores_csv_means_std, macro_score_insert,micro_score_insert,weighted_score_insert)\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pushing Data into Elastic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ES_Metric_Insert(run_id_insert,algorithm_name, test_parameters, gs_best_parameters_pipe_spam_ham, score, test_scores_csv_means_std, macro_scores, micro_scores, weighted_scores):\n",
    "    es = Elasticsearch()\n",
    "    \n",
    "    final_dict = {}\n",
    "    \n",
    "    my_current_time = datetime.now(tz=pytz.utc)\n",
    "    timestamp_insert = {'timestamp': my_current_time}\n",
    "    author_insert = {'author': 'Rahul'}\n",
    "    final_dict.update(run_id_insert)\n",
    "    final_dict.update(timestamp_insert)\n",
    "    final_dict.update(author_insert)\n",
    "    final_dict.update(algorithm_name)\n",
    "    final_dict.update(test_parameters)\n",
    "    final_dict.update(gs_best_parameters_pipe_spam_ham)\n",
    "    final_dict.update(score)\n",
    "    final_dict.update(test_scores_csv_means_std)\n",
    "    final_dict.update(macro_scores)\n",
    "    final_dict.update(micro_scores)\n",
    "    final_dict.update(weighted_scores)\n",
    "        \n",
    "    res = es.index(index=\"ml-performance-metrics\", doc_type='text', body=final_dict)\n",
    "    es.indices.refresh(index=\"ml-performance-metrics\")\n",
    "\n",
    "\n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the ML Pipeline and Calculate Metrics (using another function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_Pipeline_Processing_And_Metrics(run_id,X_train, y_train, X_test, y_test, grid_search_parameters, gs_clf_pipe_spam_ham, cv_value, classifier_name):\n",
    "    \n",
    "    gs_clf_pipe_spam_ham.fit(X_train, y_train)\n",
    "\n",
    "    ## Find predictions for the pipeline\n",
    "    y_pred = gs_clf_pipe_spam_ham.predict(X_test)\n",
    "    \n",
    "    ## Find score of predictions\n",
    "    score_pipe_spam_ham = gs_clf_pipe_spam_ham.score(X_test, y_test) * 100 \n",
    "    \n",
    "    ## Best Grid Search Parameters selected for this case    \n",
    "    gs_best_parameters_pipe_spam_ham = {}\n",
    "    for param_name in sorted(grid_search_parameters.keys()):\n",
    "        gs_best_parameters_pipe_spam_ham[param_name] = gs_clf_pipe_spam_ham.best_params_[param_name]\n",
    "        \n",
    "    \n",
    "    ## Setting up for reporting to Screen and ElasticSearch\n",
    "    \n",
    "    ## Add Run Id for each run. This helps with fishing out the correct dataset in cloud\n",
    "    run_id_insert = {'run_id' : run_id}\n",
    "    \n",
    "    ## Save Classifier name as a string\n",
    "    \n",
    "    classifier_string = str(classifier_name)\n",
    "    classifer_name_only = classifier_string.split(\"(\")[0]\n",
    "    \n",
    "    algorithm_name_insert = {'Algorithm_Name' : classifer_name_only}\n",
    "    \n",
    "    ## Add Classifier Parameters to output\n",
    "    test_parameters_insert = {'test_parameters' : str(pipe_spam_ham)}\n",
    "    \n",
    "    \n",
    "    ## Breaking test cv scores and calculating mean and standard Deviation of each.\n",
    "    cv_scores_df = pd.DataFrame.from_dict(gs_clf_pipe_spam_ham.cv_results_)\n",
    "    \n",
    "    test_scores_csv_means_std = {}\n",
    "    \n",
    "    test_scores_csv_means_std['mean_fit_time'] = cv_scores_df.loc[0 ,'mean_fit_time']\n",
    "    test_scores_csv_means_std['std_fit_time'] = cv_scores_df.loc[0 ,'std_fit_time']\n",
    "    test_scores_csv_means_std['mean_test_score'] = cv_scores_df.loc[0 ,'mean_test_score'] * 100\n",
    "    test_scores_csv_means_std['std_test_score'] = cv_scores_df.loc[0 ,'std_test_score']\n",
    "    test_scores_csv_means_std['mean_train_score'] = cv_scores_df.loc[0 ,'mean_train_score']  * 100\n",
    "    test_scores_csv_means_std['std_train_score'] = cv_scores_df.loc[0 ,'std_train_score']\n",
    "    \n",
    "\n",
    "    ## Send all the collected data to the metric collection and ES insert system.\n",
    "    calculate_metrics_push_to_es(run_id_insert, algorithm_name_insert, test_parameters_insert, gs_best_parameters_pipe_spam_ham, score_pipe_spam_ham, test_scores_csv_means_std, y_test,y_pred)\n",
    "    \n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Vectorizers and ML Algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_vectorizer_ml_algo(vector_ml_keyword):\n",
    "    \n",
    "    ## Remove from gridsearch\n",
    "    for key in grid_search_parameters.copy():\n",
    "         if vector_ml_keyword in key.lower():\n",
    "            del grid_search_parameters[key]\n",
    "    \n",
    "    \n",
    "    ## Remove from spam ham pipeline\n",
    "    \n",
    "    for item in pipe_spam_ham_features:\n",
    "        if vector_ml_keyword in item:\n",
    "            pipe_spam_ham_features.remove(item)\n",
    "    \n",
    "    return()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Count Vectorizer and associated Features for Testing\n",
    "def add_count_vectorizer(pipe_spam_ham_features,grid_search_parameters):\n",
    "    \n",
    "    grid_search_parameters['vect__stop_words'] = ('english',None)\n",
    "    grid_search_parameters['vect__ngram_range'] = [(1, 1),(1, 2),(1, 3), (1, 4)]\n",
    "    grid_search_parameters['vect__max_df'] = (0.9,1)\n",
    "    grid_search_parameters['vect__lowercase'] = (True, False)\n",
    "    grid_search_parameters['vect__binary'] = (True, False)\n",
    "#   grid_search_parameters['vect__tokenizer'] = (LemmaTokenizer())\n",
    "\n",
    "    pipe_spam_ham_features.append(('vect', CountVectorizer()))\n",
    "\n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Tf-Idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Tf-Idf Vectorizer and associated Features for Testing\n",
    "def add_tfidf_vectorizer(pipe_spam_ham_features,grid_search_parameters):\n",
    "    \n",
    "    grid_search_parameters['tfidf__use_idf'] = (True, False)\n",
    "    grid_search_parameters['tfidf__norm'] = ('l1','l2','max')\n",
    "    grid_search_parameters['tfidf__use_idf'] = (True, False)\n",
    "    grid_search_parameters['tfidf__smooth_idf'] = (True, False)\n",
    "    grid_search_parameters['tfidf__sublinear_tf'] = (True, False)\n",
    "\n",
    "    pipe_spam_ham_features.append(('vect', CountVectorizer()))\n",
    "    \n",
    "\n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Naive Bayes Algorithm\n",
    "def add_multinomialNB(pipe_spam_ham_features,grid_search_parameters):\n",
    "    \n",
    "    grid_search_parameters['nb__alpha'] = (0,1)\n",
    "    grid_search_parameters['nb__fit_prior'] = (True, False)\n",
    "    \n",
    "    \n",
    "    pipe_spam_ham_features.append(('nb', MultinomialNB()))\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Naive Bayes Algorithm\n",
    "def add_knn(pipe_spam_ham_features,grid_search_parameters):\n",
    "    \n",
    "    grid_search_parameters['knn__n_neighbors'] = (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15)\n",
    "    grid_search_parameters['knn__weights'] = ('uniform', 'distance')\n",
    "    grid_search_parameters['knn__algorithm'] = ('ball_tree', 'kd_tree')\n",
    "    \n",
    "    pipe_spam_ham_features.append(('knn', KNeighborsClassifier()))\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add Code [('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None))]\n",
      "Add Code {'vect__stop_words': ('english', None), 'vect__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)], 'vect__max_df': (0.9, 1), 'vect__lowercase': (True, False), 'vect__binary': (True, False)}\n",
      "Remove Code []\n",
      "Remove Code {}\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-1d378f2ffa64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m## Addition of TfIdf Vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mlist_tfidf_vect_pipe_and_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_tfidf_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe_spam_ham_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid_search_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mpipe_spam_ham_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_tfidf_vect_pipe_and_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_tfidf_vect_pipe_and_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mgrid_search_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_tfidf_vect_pipe_and_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "pipe_spam_ham = []\n",
    "pipe_spam_ham_features = []\n",
    "grid_search_parameters = {}\n",
    "\n",
    "run_id = randint(100000, 999999)\n",
    "\n",
    "## Cross_Val value\n",
    "cv_value = 2\n",
    "\n",
    "# Define 10 fold cross-validation\n",
    "cv = KFold(n_splits=10)\n",
    "\n",
    "\n",
    "\n",
    "## Kick off the pipeline Execution:\n",
    "\n",
    "## Iteration 1:\n",
    "## CountVectorizer only\n",
    "## CountVectorizer + ML Algorithms\n",
    "## TFIdf only\n",
    "## TFIdf and ML Algorithms\n",
    "\n",
    "## CountVectorizer + TFIdf + ML Algorithms \n",
    "\n",
    "\n",
    "\n",
    "## Addition of Count Vectorizer\n",
    "add_count_vectorizer(pipe_spam_ham_features,grid_search_parameters)\n",
    "\n",
    "## Remove Count Vectorizer\n",
    "remove_vectorizer_ml_algo('vect')\n",
    "\n",
    "## Addition of TfIdf Vectorizer\n",
    "add_tfidf_vectorizer(pipe_spam_ham_features,grid_search_parameters)\n",
    "\n",
    "## Remove TfIdf Vectorizer\n",
    "remove_vectorizer_ml_algo('tfidf')\n",
    "\n",
    "\n",
    "## Adding Algorithms:\n",
    "\n",
    "## Addition of MultinomialNB Algorithm\n",
    "add_multinomialNB(pipe_spam_ham_features,grid_search_parameters)\n",
    "\n",
    "## Remove MultinomialNB Vectorizer\n",
    "remove_vectorizer_ml_algo('nb')\n",
    "\n",
    "## Addition of knn Algorithm\n",
    "add_knn(pipe_spam_ham_features,grid_search_parameters):\n",
    "\n",
    "## Remove knn\n",
    "remove_vectorizer_ml_algo('knn')\n",
    "\n",
    "\n",
    "#pipe_spam_ham_features.append(('hash', HashingVectorizer()))\n",
    "\n",
    "\n",
    "\n",
    "## Initializing the classifier to Naieve Bayes\n",
    "pipe_spam_ham_features.append(('clf', MultinomialNB()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## Putting together the various classification algorithms to use\n",
    "# clfs = []\n",
    "# clfs.append(MultinomialNB())\n",
    "# clfs.append(SVC())\n",
    "# clfs.append(KNeighborsClassifier(n_neighbors=5))\n",
    "# clfs.append(DecisionTreeClassifier())\n",
    "# clfs.append(RandomForestClassifier())\n",
    "# clfs.append(GradientBoostingClassifier())\n",
    "# clfs.append(LogisticRegression())\n",
    "\n",
    "\n",
    "## Setting up the pipeline\n",
    "pipe_spam_ham = Pipeline(pipe_spam_ham_features)\n",
    "\n",
    "\n",
    "\n",
    "## Trying out the various possible classifiers:\n",
    "\n",
    "for classifier in clfs:\n",
    "    \n",
    "    ## Adding the classifier to be used\n",
    "    pipe_spam_ham.set_params(clf = classifier)\n",
    "    \n",
    "    gs_clf_pipe_spam_ham = GridSearchCV(pipe_spam_ham, grid_search_parameters, n_jobs=-1, cv=cv_value, return_train_score=True)\n",
    "    \n",
    "    ML_Pipeline_Processing_And_Metrics(run_id,X_train, y_train, X_test, y_test,grid_search_parameters, gs_clf_pipe_spam_ham, cv_value, classifier)\n",
    "    \n",
    "    \n",
    "\n",
    "##                          'vect__analyzer': (‘word’, ‘char’, ‘char_wb’),\n",
    "##                          'vect__preprocessor: ('callable','None'),\n",
    "##                          'vect__tokenizer: (LemmaTokenizer()),\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
